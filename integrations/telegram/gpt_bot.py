"""
Telegram –±–æ—Ç AI Business Auditor —Å –Ω–∞—Å—Ç–æ—è—â–∏–º GPT –∞–Ω–∞–ª–∏–∑–æ–º
–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –∏–∑ config.py
"""

import os
import sys
import logging
import pandas as pd
import tempfile
import random
import hashlib
import sqlite3
import shutil
import atexit
import re
from datetime import datetime, timedelta
from pathlib import Path
from contextlib import contextmanager
from functools import lru_cache
from typing import Dict, Any, Optional, List, Tuple

import os
import sys
import logging
import asyncio
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–ø—É—â–µ–Ω –ª–∏ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
def is_in_container():
    return os.getenv('RENDER') == 'true' or os.path.exists('/.dockerenv')


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –±–æ—Ç–∞"""
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
        from integrations.telegram.config import TELEGRAM_BOT_TOKEN, BOT_CONFIG
        from telegram.ext import Application

        if not TELEGRAM_BOT_TOKEN:
            logger.error("‚ùå TELEGRAM_BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return

        logger.info(f"ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Telegram –±–æ—Ç–∞...")
        logger.info(f"‚è∞ –í—Ä–µ–º—è –∑–∞–ø—É—Å–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
        application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
        from integrations.telegram.handlers import setup_handlers
        setup_handlers(application)

        logger.info("‚úÖ –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã")

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ polling
        await application.initialize()
        await application.start()

        if is_in_container():
            logger.info("üöÄ –ó–∞–ø—É—Å–∫ –≤ —Ä–µ–∂–∏–º–µ polling (–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä)...")
            await application.updater.start_polling(
                drop_pending_updates=BOT_CONFIG.get("skip_updates", True),
                timeout=BOT_CONFIG.get("timeout", 30)
            )
        else:
            logger.info("üöÄ –ó–∞–ø—É—Å–∫ –≤ —Ä–µ–∂–∏–º–µ polling (–ª–æ–∫–∞–ª—å–Ω–æ)...")
            await application.updater.start_polling()

        logger.info("‚úÖ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
        logger.info(f"üë§ –ò–º—è –±–æ—Ç–∞: @{(await application.bot.get_me()).username}")

        # –ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π —Ü–∏–∫–ª –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
        while True:
            await asyncio.sleep(3600)  # –°–ø–∏–º 1 —á–∞—Å

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –±–æ—Ç–∞: {e}")
        raise


if __name__ == "__main__":
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    required_vars = ['TELEGRAM_BOT_TOKEN']
    missing = [var for var in required_vars if not os.getenv(var)]

    if missing:
        logger.warning(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ: {missing}")
        logger.info("üí° Telegram –±–æ—Ç –Ω–µ –±—É–¥–µ—Ç –∑–∞–ø—É—â–µ–Ω –±–µ–∑ TELEGRAM_BOT_TOKEN")
        sys.exit(0)  # –ù–µ –ø–∞–¥–∞–µ–º, –ø—Ä–æ—Å—Ç–æ –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞

    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("üõë –ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞: {e}")


# ========== –ù–ê–°–¢–†–û–ô–ö–ê –ü–£–¢–ï–ô –ò –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò ==========
# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
current_dir = Path(__file__).parent.absolute()
if str(current_dir) not in sys.path:
    sys.path.insert(0, str(current_dir))

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
try:
    from config import config as bot_config

    TOKEN = bot_config.TOKEN
    ADMIN_ID = bot_config.ADMIN_ID
    MAX_FILE_SIZE = bot_config.MAX_FILE_SIZE
    ALLOWED_EXTENSIONS = bot_config.ALLOWED_EXTENSIONS

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    if not bot_config.validate():
        print("‚ö†Ô∏è  –í–Ω–∏–º–∞–Ω–∏–µ: –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç, –±–æ—Ç –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ–ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ")
        print("   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å .env —Ñ–∞–π–ª")

except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ config: {e}")
    print("‚ö†Ô∏è  –ó–∞–≤–µ—Ä—à–∞—é —Ä–∞–±–æ—Ç—É - —Ç—Ä–µ–±—É–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è")
    sys.exit(1)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–∫–µ–Ω –±–æ—Ç–∞
if not TOKEN or TOKEN == "your_actual_bot_token_here":
    print("‚ùå –û–®–ò–ë–ö–ê: –¢–æ–∫–µ–Ω –±–æ—Ç–∞ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω!")
    print("   –î–æ–±–∞–≤—å—Ç–µ TELEGRAM_BOT_TOKEN –≤ .env —Ñ–∞–π–ª")
    print("   –ü–æ–ª—É—á–∏—Ç–µ –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω —á–µ—Ä–µ–∑ @BotFather –µ—Å–ª–∏ —Å—Ç–∞—Ä—ã–π –±—ã–ª —Å–∫–æ–º–ø—Ä–æ–º–µ—Ç–∏—Ä–æ–≤–∞–Ω")
    sys.exit(1)

# ========== –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–ì–ò–†–û–í–ê–ù–ò–Ø ==========
# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
logs_dir = bot_config.LOGS_DIR if hasattr(bot_config, 'LOGS_DIR') else Path("logs")
logs_dir.mkdir(exist_ok=True, parents=True)

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO,
    handlers=[
        logging.FileHandler(logs_dir / 'telegram_bot.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Telegram –∏–º–ø–æ—Ä—Ç—ã
from telegram import Update, ReplyKeyboardMarkup, KeyboardButton, InlineKeyboardMarkup, InlineKeyboardButton
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackQueryHandler, filters, ContextTypes


# ========== –£–¢–ò–õ–ò–¢–´ –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò –¢–ï–ö–°–¢–ê ==========
def escape_markdown(text: str) -> str:
    """–≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ Markdown –¥–ª—è Telegram"""
    if not text:
        return text

    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã Markdown
    special_chars = r'_*[]()~`>#+-=|{}.!'
    for char in special_chars:
        text = text.replace(char, f'\\{char}')

    return text


def sanitize_markdown(text: str) -> str:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Markdown"""
    # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    text = re.sub(r'(\*){3,}', '**', text)  # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–≤–µ–∑–¥–æ—á–∫–∏
    text = re.sub(r'(_{3,})', '__', text)  # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è
    text = re.sub(r'(`){3,}', '`', text)  # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ–±—Ä–∞—Ç–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏

    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤—Å–µ —Ç–µ–≥–∏ –ø–∞—Ä–Ω—ã–µ
    tags = [('**', '**'), ('__', '__'), ('`', '`'), ('*', '*'), ('_', '_')]

    for open_tag, close_tag in tags:
        # –°—á–∏—Ç–∞–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–µ –∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ —Ç–µ–≥–∏
        open_count = text.count(open_tag)
        close_count = text.count(close_tag)

        # –ï—Å–ª–∏ –Ω–µ—á–µ—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–π —Ç–µ–≥
        if open_count > close_count:
            text += close_tag
        elif close_count > open_count:
            text = open_tag + text

    return text


def truncate_text(text: str, max_length: int = 3500, suffix: str = "...") -> str:
    """–û–±—Ä–µ–∑–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å —É—á–µ—Ç–æ–º Markdown"""
    if len(text) <= max_length:
        return text

    # –ò—â–µ–º –º–µ—Å—Ç–æ –¥–ª—è –æ–±—Ä–µ–∑–∫–∏ –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–æ–±–µ–ª–∞ –∏–ª–∏ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏
    truncate_point = text.rfind('\n', 0, max_length - len(suffix))
    if truncate_point == -1:
        truncate_point = text.rfind(' ', 0, max_length - len(suffix))
    if truncate_point == -1:
        truncate_point = max_length - len(suffix)

    truncated = text[:truncate_point] + suffix

    # –ó–∞–∫—Ä—ã–≤–∞–µ–º –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ Markdown —Ç–µ–≥–∏
    return sanitize_markdown(truncated)


# ========== –ú–ï–ù–ï–î–ñ–ï–† –ë–ê–ó–´ –î–ê–ù–ù–´–• ==========
class DatabaseManager:
    def __init__(self, db_path: str = "bot_data.db"):
        self.db_path = Path(db_path)
        self.init_db()

    def get_connection(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        return conn

    def init_db(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        with self.get_connection() as conn:
            # –¢–∞–±–ª–∏—Ü–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            conn.execute("""
                CREATE TABLE IF NOT EXISTS users (
                    user_id INTEGER PRIMARY KEY,
                    username TEXT,
                    first_name TEXT,
                    last_name TEXT,
                    language_code TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    last_active TIMESTAMP
                )
            """)

            # –¢–∞–±–ª–∏—Ü–∞ –∞–Ω–∞–ª–∏–∑–æ–≤
            conn.execute("""
                CREATE TABLE IF NOT EXISTS analyses (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER,
                    filename TEXT,
                    file_hash TEXT,
                    record_count INTEGER,
                    columns_count INTEGER,
                    analysis_type TEXT,
                    gpt_used BOOLEAN DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users (user_id)
                )
            """)

            # –¢–∞–±–ª–∏—Ü–∞ rate limits
            conn.execute("""
                CREATE TABLE IF NOT EXISTS rate_limits (
                    user_id INTEGER PRIMARY KEY,
                    gpt_requests_today INTEGER DEFAULT 0,
                    last_gpt_request TIMESTAMP,
                    reset_date DATE,
                    FOREIGN KEY (user_id) REFERENCES users (user_id)
                )
            """)

            conn.commit()

    def save_user(self, user_id: int, username: str, first_name: str, last_name: str, language_code: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–ª–∏ –æ–±–Ω–æ–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        with self.get_connection() as conn:
            conn.execute("""
                INSERT OR REPLACE INTO users 
                (user_id, username, first_name, last_name, language_code, last_active)
                VALUES (?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
            """, (user_id, username, first_name, last_name, language_code))
            conn.commit()

    def log_analysis(self, user_id: int, filename: str, file_hash: str, record_count: int,
                     columns_count: int, analysis_type: str, gpt_used: bool = False):
        """–ó–∞–ø–∏—Å–∞—Ç—å –∞–Ω–∞–ª–∏–∑ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        with self.get_connection() as conn:
            conn.execute("""
                INSERT INTO analyses 
                (user_id, filename, file_hash, record_count, columns_count, analysis_type, gpt_used)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (user_id, filename, file_hash, record_count, columns_count, analysis_type, gpt_used))
            conn.commit()

    def check_rate_limit(self, user_id: int) -> tuple:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å rate limit –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        with self.get_connection() as conn:
            cursor = conn.execute("""
                SELECT gpt_requests_today, last_gpt_request, reset_date
                FROM rate_limits WHERE user_id = ?
            """, (user_id,))
            row = cursor.fetchone()

            today = datetime.now().date()

            if row is None:
                # –°–æ–∑–¥–∞—Ç—å –∑–∞–ø–∏—Å—å
                conn.execute("""
                    INSERT INTO rate_limits (user_id, reset_date)
                    VALUES (?, ?)
                """, (user_id, today))
                conn.commit()
                return 0, None, today

            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω—É–∂–Ω–æ –ª–∏ —Å–±—Ä–æ—Å–∏—Ç—å —Å—á–µ—Ç—á–∏–∫
            reset_date = datetime.strptime(row['reset_date'], '%Y-%m-%d').date() if isinstance(row['reset_date'],
                                                                                               str) else row[
                'reset_date']

            if today > reset_date:
                # –°–±—Ä–æ—Å–∏—Ç—å —Å—á–µ—Ç—á–∏–∫
                conn.execute("""
                    UPDATE rate_limits 
                    SET gpt_requests_today = 0, reset_date = ?
                    WHERE user_id = ?
                """, (today, user_id))
                conn.commit()
                return 0, row['last_gpt_request'], today

            return row['gpt_requests_today'], row['last_gpt_request'], reset_date

    def increment_gpt_requests(self, user_id: int):
        """–£–≤–µ–ª–∏—á–∏—Ç—å —Å—á–µ—Ç—á–∏–∫ GPT –∑–∞–ø—Ä–æ—Å–æ–≤"""
        with self.get_connection() as conn:
            conn.execute("""
                UPDATE rate_limits 
                SET gpt_requests_today = gpt_requests_today + 1,
                    last_gpt_request = CURRENT_TIMESTAMP
                WHERE user_id = ?
            """, (user_id,))
            conn.commit()

    def get_user_stats(self, user_id: int) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        with self.get_connection() as conn:
            cursor = conn.execute("""
                SELECT 
                    COUNT(*) as total_analyses,
                    SUM(CASE WHEN gpt_used = 1 THEN 1 ELSE 0 END) as gpt_analyses,
                    MAX(created_at) as last_analysis
                FROM analyses 
                WHERE user_id = ?
            """, (user_id,))
            row = cursor.fetchone()

            return {
                'total_analyses': row['total_analyses'] if row else 0,
                'gpt_analyses': row['gpt_analyses'] if row else 0,
                'last_analysis': row['last_analysis']
            }

    def get_admin_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
        with self.get_connection() as conn:
            cursor = conn.execute("""
                SELECT 
                    COUNT(DISTINCT user_id) as total_users,
                    COUNT(*) as total_analyses,
                    SUM(CASE WHEN gpt_used = 1 THEN 1 ELSE 0 END) as total_gpt_analyses,
                    DATE(created_at) as date,
                    COUNT(*) as daily_count
                FROM analyses 
                GROUP BY DATE(created_at)
                ORDER BY date DESC
                LIMIT 7
            """)

            daily_stats = cursor.fetchall()

            cursor = conn.execute("""
                SELECT COUNT(*) as active_users
                FROM users 
                WHERE last_active > DATE('now', '-7 days')
            """)
            active_users = cursor.fetchone()['active_users']

            return {
                'total_users': daily_stats[0]['total_users'] if daily_stats else 0,
                'total_analyses': daily_stats[0]['total_analyses'] if daily_stats else 0,
                'total_gpt_analyses': daily_stats[0]['total_gpt_analyses'] if daily_stats else 0,
                'active_users': active_users,
                'daily_stats': daily_stats
            }


# ========== –ò–ú–ü–û–†–¢ –í–ê–®–ò–• –ú–û–î–£–õ–ï–ô ==========
GPT_AVAILABLE = False
try:
    print("üîç –ò–º–ø–æ—Ä—Ç DataAnalyzer —á–µ—Ä–µ–∑ –∞–¥–∞–ø—Ç–µ—Ä...")

    # –ü—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∞–¥–∞–ø—Ç–µ—Ä
    try:
        from analyzer_adapter import analyzer as gpt_analyzer

        print("‚úÖ –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π DataAnalyzer –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
        GPT_AVAILABLE = True
    except ImportError:
        # –ï—Å–ª–∏ –∞–¥–∞–ø—Ç–µ—Ä–∞ –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º –Ω–∞–ø—Ä—è–º—É—é
        print("‚ö†Ô∏è  –ê–¥–∞–ø—Ç–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É—é –ø—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç...")

        # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ agents
        project_root = current_dir.parent.parent
        agents_path = project_root / "agents"
        if str(agents_path) not in sys.path:
            sys.path.insert(0, str(agents_path))

        from analyzer import DataAnalyzer

        print("‚úÖ DataAnalyzer –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –Ω–∞–ø—Ä—è–º—É—é")


        # –°–æ–∑–¥–∞–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º—É—é –æ–±–µ—Ä—Ç–∫—É
        class CompatibleDataAnalyzer:
            def __init__(self):
                self.analyzer = DataAnalyzer()

            def basic_analysis(self, df):
                result = self.analyzer.basic_analysis(df)
                # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –ø–æ–ª–µ–π
                if isinstance(result, dict):
                    if 'trends' not in result:
                        result['trends'] = []
                    if 'financial_metrics' not in result:
                        result['financial_metrics'] = {}
                return result

            def gpt_analysis(self, df):
                try:
                    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—ã–∑–æ–≤–∞
                    try:
                        return self.analyzer.gpt_analysis(df)
                    except TypeError as e:
                        if "missing" in str(e) and "required" in str(e):
                            # –ù—É–∂–Ω—ã trends –∏ financial_metrics
                            basic = self.basic_analysis(df)
                            trends = basic.get('trends', [])
                            financial_metrics = basic.get('financial_metrics', {})
                            return self.analyzer.gpt_analysis(df, trends=trends, financial_metrics=financial_metrics)
                        else:
                            raise e
                except Exception as e:
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ–º–æ-–∞–Ω–∞–ª–∏–∑ –ø—Ä–∏ –æ—à–∏–±–∫–µ
                    return self._get_fallback_analysis(df)

            def _get_fallback_analysis(self, df):
                numeric_cols = df.select_dtypes(include='number').columns
                if len(numeric_cols) > 0:
                    response = "*GPT –ê–Ω–∞–ª–∏–∑ (—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ä–µ–∂–∏–º)*\n\n"
                    response += "*–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã:*\n"
                    for col in numeric_cols[:2]:
                        mean_val = df[col].mean()
                        response += f"‚Ä¢ {col}: —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ {mean_val:,.2f}\n"
                    return response
                else:
                    return "*GPT –ê–Ω–∞–ª–∏–∑:* –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"


        gpt_analyzer = CompatibleDataAnalyzer()
        GPT_AVAILABLE = True

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å OpenAI API
    if hasattr(bot_config, 'OPENAI_API_KEY') and bot_config.OPENAI_API_KEY:
        print("üîë OpenAI API –∫–ª—é—á –æ–±–Ω–∞—Ä—É–∂–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
    else:
        print("‚ö†Ô∏è  OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, GPT –∞–Ω–∞–ª–∏–∑ –º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å")

except ImportError as e:
    print(f"‚ö†Ô∏è  DataAnalyzer –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")
    print("‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ–º–æ-—Ä–µ–∂–∏–º GPT –∞–Ω–∞–ª–∏–∑–∞")


    # –î–µ–º–æ-–∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    class DemoAnalyzer:
        def basic_analysis(self, df):
            return {
                'record_count': len(df),
                'columns': list(df.columns),
                'summary': '–î–µ–º–æ-–∞–Ω–∞–ª–∏–∑: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–µ–±-–≤–µ—Ä—Å–∏—é –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞',
                'trends': [],
                'financial_metrics': {},
                'recommendations': ['–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è GPT –∞–Ω–∞–ª–∏–∑–∞']
            }

        def gpt_analysis(self, df):
            numeric_cols = df.select_dtypes(include='number').columns

            if len(numeric_cols) > 0:
                response = "*GPT –ê–Ω–∞–ª–∏–∑ (–¥–µ–º–æ-—Ä–µ–∂–∏–º)*\n\n"
                response += "*–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã:*\n"

                for col in numeric_cols[:2]:
                    mean_val = df[col].mean()
                    response += f"‚Ä¢ {col}: —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ {mean_val:,.2f}\n"

                response += "\n*–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:*\n"
                response += "1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ GPT –∞–Ω–∞–ª–∏–∑–∞\n"
                response += "2. –î–æ–±–∞–≤—å—Ç–µ OpenAI API –∫–ª—é—á –≤ .env —Ñ–∞–π–ª\n"
                response += "3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å AmoCRM\n"

                return response
            else:
                return "*GPT –ê–Ω–∞–ª–∏–∑:* –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"


    gpt_analyzer = DemoAnalyzer()


# ========== –ö–õ–ê–í–ò–ê–¢–£–†–´ ==========
def get_main_menu():
    """–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"""
    keyboard = [
        [KeyboardButton("üìä –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞"), KeyboardButton("ü§ñ GPT –ê–Ω–∞–ª–∏–∑")],
        [KeyboardButton("üìà –ì—Ä–∞—Ñ–∏–∫–∏"), KeyboardButton("üìã –û—Ç—á–µ—Ç")],
        [KeyboardButton("üè¢ AmoCRM"), KeyboardButton("üí° –°–æ–≤–µ—Ç—ã")],
        [KeyboardButton("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏"), KeyboardButton("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")],
        [KeyboardButton("‚ùì –ü–æ–º–æ—â—å"), KeyboardButton("‚ùå –û—Ç–º–µ–Ω–∞")]
    ]
    return ReplyKeyboardMarkup(keyboard, resize_keyboard=True)


def get_analysis_menu():
    """–ú–µ–Ω—é –∞–Ω–∞–ª–∏–∑–∞"""
    buttons = [
        [
            InlineKeyboardButton("üìä –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑", callback_data="quick"),
            InlineKeyboardButton("ü§ñ GPT –ê–Ω–∞–ª–∏–∑", callback_data="gpt")
        ],
        [
            InlineKeyboardButton("üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è", callback_data="viz"),
            InlineKeyboardButton("üìã –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç", callback_data="full_report")
        ],
        [
            InlineKeyboardButton("üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏", callback_data="recommend"),
            InlineKeyboardButton("üîç –î–µ—Ç–∞–ª–∏", callback_data="details")
        ],
        [
            InlineKeyboardButton("üìä –ú–æ—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", callback_data="my_stats"),
            InlineKeyboardButton("üîô –ù–∞–∑–∞–¥", callback_data="back_to_main")
        ]
    ]
    return InlineKeyboardMarkup(buttons)


def get_gpt_settings_menu():
    """–ú–µ–Ω—é –Ω–∞—Å—Ç—Ä–æ–µ–∫ GPT"""
    buttons = [
        [InlineKeyboardButton("üîë –ù–∞—Å—Ç—Ä–æ–∏—Ç—å API –∫–ª—é—á", callback_data="set_api_key")],
        [InlineKeyboardButton("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏", callback_data="set_model")],
        [InlineKeyboardButton("üìä –ö–æ–Ω—Ç–µ–∫—Å—Ç –∞–Ω–∞–ª–∏–∑–∞", callback_data="set_context")],
        [InlineKeyboardButton("üîô –ù–∞–∑–∞–¥", callback_data="back_to_main")]
    ]
    return InlineKeyboardMarkup(buttons)


def get_cancel_menu():
    """–ú–µ–Ω—é –æ—Ç–º–µ–Ω—ã"""
    buttons = [
        [InlineKeyboardButton("‚ùå –û—Ç–º–µ–Ω–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏—é", callback_data="cancel_operation")]
    ]
    return InlineKeyboardMarkup(buttons)


def get_model_settings_menu():
    """–ú–µ–Ω—é –Ω–∞—Å—Ç—Ä–æ–µ–∫ –º–æ–¥–µ–ª–∏"""
    buttons = [
        [
            InlineKeyboardButton("GPT-3.5 Turbo", callback_data="model_gpt35"),
            InlineKeyboardButton("GPT-4", callback_data="model_gpt4")
        ],
        [
            InlineKeyboardButton("GPT-4 Turbo", callback_data="model_gpt4t"),
            InlineKeyboardButton("GPT-4o", callback_data="model_gpt4o")
        ],
        [
            InlineKeyboardButton("üîô –ù–∞–∑–∞–¥ –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º", callback_data="back_to_settings")
        ]
    ]
    return InlineKeyboardMarkup(buttons)


# ========== –û–°–ù–û–í–ù–û–ô –ö–õ–ê–°–° –ë–û–¢–ê ==========
class GPTBusinessBot:
    def __init__(self):
        self.analyzer = gpt_analyzer
        self.user_data = {}
        self.db = DatabaseManager()
        self.temp_dir = bot_config.TEMP_DIR if hasattr(bot_config, 'TEMP_DIR') else Path("temp")
        self.temp_dir.mkdir(exist_ok=True, parents=True)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ rate limit
        self.MAX_GPT_REQUESTS_PER_DAY = getattr(bot_config, 'MAX_GPT_REQUESTS_PER_DAY', 50)
        self.GPT_COOLDOWN_SECONDS = getattr(bot_config, 'GPT_COOLDOWN_SECONDS', 30)

        self.gpt_settings = {
            'model': bot_config.OPENAI_MODEL if hasattr(bot_config, 'OPENAI_MODEL') else 'gpt-3.5-turbo',
            'temperature': 0.7,
            'max_tokens': 1000
        }

        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ—á–∏—Å—Ç–∫—É –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
        atexit.register(self.cleanup)

        print("=" * 60)
        print("ü§ñ GPT BUSINESS AUDITOR BOT")
        print(f"‚úÖ Token: {'–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω' if TOKEN and TOKEN != 'your_actual_bot_token_here' else '–ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω'}")
        print(f"üìä GPT –∞–Ω–∞–ª–∏–∑: {'–î–û–°–¢–£–ü–ï–ù' if GPT_AVAILABLE else '–î–ï–ú–û-–†–ï–ñ–ò–ú'}")
        print(f"üë§ –ê–¥–º–∏–Ω ID: {ADMIN_ID if ADMIN_ID else '–ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω'}")
        print(f"üóÑÔ∏è  –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {self.db.db_path}")
        print("=" * 60)

    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏"""
        try:
            if self.temp_dir.exists():
                shutil.rmtree(self.temp_dir)
                logger.info("–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –æ—á–∏—â–µ–Ω—ã")
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {e}")

    def create_data_hash(self, df: pd.DataFrame) -> str:
        """–°–æ–∑–¥–∞—Ç—å —Ö–µ—à –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
        try:
            return hashlib.md5(pd.util.hash_pandas_object(df).values.tobytes()).hexdigest()
        except:
            # Fallback –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            return hashlib.md5(str(df.shape).encode() + str(df.columns.tolist()).encode()).hexdigest()

    @lru_cache(maxsize=100)
    def get_cached_analysis(self, data_hash: str, analysis_type: str) -> Optional[str]:
        """–ü–æ–ª—É—á–∏—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑"""
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—ã–ª–æ –±—ã –æ–±—Ä–∞—â–µ–Ω–∏–µ –∫ Redis –∏–ª–∏ –¥—Ä—É–≥–æ–π –∫—ç—à-—Å–∏—Å—Ç–µ–º–µ
        return None

    async def check_gpt_rate_limit(self, user_id: int) -> tuple:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å rate limit –¥–ª—è GPT –∑–∞–ø—Ä–æ—Å–æ–≤"""
        requests_today, last_request, reset_date = self.db.check_rate_limit(user_id)

        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å daily limit
        if requests_today >= self.MAX_GPT_REQUESTS_PER_DAY:
            reset_time = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0) + timedelta(days=1)
            time_left = reset_time - datetime.now()
            return False, f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –¥–Ω–µ–≤–Ω–æ–π –ª–∏–º–∏—Ç ({self.MAX_GPT_REQUESTS_PER_DAY} –∑–∞–ø—Ä–æ—Å–æ–≤).\n–õ–∏–º–∏—Ç —Å–±—Ä–æ—Å–∏—Ç—Å—è —á–µ—Ä–µ–∑ {time_left.seconds // 3600} —á. {(time_left.seconds % 3600) // 60} –º–∏–Ω."

        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å cooldown
        if last_request:
            last_request_time = datetime.strptime(last_request, '%Y-%m-%d %H:%M:%S') if isinstance(last_request,
                                                                                                   str) else last_request
            time_since_last = datetime.now() - last_request_time

            if time_since_last.total_seconds() < self.GPT_COOLDOWN_SECONDS:
                wait_time = self.GPT_COOLDOWN_SECONDS - time_since_last.total_seconds()
                return False, f"–ü–æ–¥–æ–∂–¥–∏—Ç–µ {int(wait_time)} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º GPT –∑–∞–ø—Ä–æ—Å–æ–º."

        return True, ""

    async def safe_send_message(self, chat_id: int, text: str,
                                parse_mode: str = None,
                                reply_markup=None,
                                context: ContextTypes.DEFAULT_TYPE = None) -> bool:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ Markdown"""
        try:
            # –û—á–∏—â–∞–µ–º Markdown
            if parse_mode == 'Markdown':
                text = sanitize_markdown(text)
                # –û–±—Ä–µ–∑–∞–µ–º –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
                text = truncate_text(text, 3500)

            await context.bot.send_message(
                chat_id=chat_id,
                text=text,
                parse_mode=parse_mode,
                reply_markup=reply_markup
            )
            return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")

            # –ü—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –±–µ–∑ Markdown
            if parse_mode == 'Markdown':
                try:
                    clean_text = escape_markdown(text)
                    clean_text = truncate_text(clean_text, 3500)

                    await context.bot.send_message(
                        chat_id=chat_id,
                        text=clean_text,
                        parse_mode=None,
                        reply_markup=reply_markup
                    )
                    return True
                except Exception as e2:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –±–µ–∑ Markdown: {e2}")

            return False

    async def safe_edit_message_text(self, message, text: str,
                                     parse_mode: str = None,
                                     reply_markup=None,
                                     context: ContextTypes.DEFAULT_TYPE = None) -> bool:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ Markdown"""
        try:
            # –û—á–∏—â–∞–µ–º Markdown
            if parse_mode == 'Markdown':
                text = sanitize_markdown(text)
                text = truncate_text(text, 3500)

            await message.edit_text(
                text=text,
                parse_mode=parse_mode,
                reply_markup=reply_markup
            )
            return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")

            # –ü—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –±–µ–∑ Markdown
            if parse_mode == 'Markdown':
                try:
                    clean_text = escape_markdown(text)
                    clean_text = truncate_text(clean_text, 3500)

                    await message.edit_text(
                        text=clean_text,
                        parse_mode=None,
                        reply_markup=reply_markup
                    )
                    return True
                except Exception as e2:
                    logger.error(f"–û—à–∏–±–∫–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑ Markdown: {e2}")

            return False

    async def safe_edit_callback_message(self, query, text: str,
                                         parse_mode: str = None,
                                         reply_markup=None) -> bool:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è callback query"""
        try:
            # –û—á–∏—â–∞–µ–º Markdown
            if parse_mode == 'Markdown':
                text = sanitize_markdown(text)
                text = truncate_text(text, 3500)

            await query.edit_message_text(
                text=text,
                parse_mode=parse_mode,
                reply_markup=reply_markup
            )
            return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è callback —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")

            # –ü—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –±–µ–∑ Markdown
            if parse_mode == 'Markdown':
                try:
                    clean_text = escape_markdown(text)
                    clean_text = truncate_text(clean_text, 3500)

                    await query.edit_message_text(
                        text=clean_text,
                        parse_mode=None,
                        reply_markup=reply_markup
                    )
                    return True
                except Exception as e2:
                    logger.error(f"–û—à–∏–±–∫–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è callback –±–µ–∑ Markdown: {e2}")

            return False

    # ========== –û–°–ù–û–í–ù–´–ï –ö–û–ú–ê–ù–î–´ ==========
    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ö–æ–º–∞–Ω–¥–∞ /start"""
        user = update.effective_user
        logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user.id} ({user.username}) –∑–∞–ø—É—Å—Ç–∏–ª –±–æ—Ç–∞")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –ë–î
        self.db.save_user(
            user_id=user.id,
            username=user.username,
            first_name=user.first_name,
            last_name=user.last_name,
            language_code=user.language_code
        )

        gpt_status = "*GPT –ê–ù–ê–õ–ò–ó –î–û–°–¢–£–ü–ï–ù*" if GPT_AVAILABLE else "*GPT –ê–ù–ê–õ–ò–ó (–¥–µ–º–æ)*"

        welcome = f"""
*–î–û–ë–†–û –ü–û–ñ–ê–õ–û–í–ê–¢–¨ –í AI BUSINESS AUDITOR!*

{gpt_status}

*–ü–û–õ–ù–´–ô –§–£–ù–ö–¶–ò–û–ù–ê–õ:*
‚Ä¢ –ê–Ω–∞–ª–∏–∑ CSV/Excel/JSON —Ñ–∞–π–ª–æ–≤
‚Ä¢ –ù–∞—Å—Ç–æ—è—â–∏–π GPT –∞–Ω–∞–ª–∏–∑ —Å AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
‚Ä¢ –î–µ—Ç–∞–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
‚Ä¢ –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã –≤ Markdown/PDF
‚Ä¢ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å AmoCRM (–¥–µ–º–æ + —Ä–µ–∞–ª—å–Ω–∞—è)

*–ü–û–õ–£–ß–ò–¢–ï GPT –ê–ù–ê–õ–ò–ó:*
1. –ù–∞–∂–º–∏—Ç–µ üìä –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞
2. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
3. –í—ã–±–µ—Ä–∏—Ç–µ ü§ñ GPT –ê–Ω–∞–ª–∏–∑
4. –ü–æ–ª—É—á–∏—Ç–µ AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

*–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—é –Ω–∏–∂–µ:*
        """

        await update.message.reply_text(
            welcome,
            reply_markup=get_main_menu(),
            parse_mode='Markdown'
        )

    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ö–æ–º–∞–Ω–¥–∞ /help"""
        help_text = """
*–ü–û–ú–û–©–¨ –ü–û GPT BUSINESS AUDITOR*

*GPT –ê–ù–ê–õ–ò–ó:*
‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç OpenAI GPT –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö
‚Ä¢ –î–∞–µ—Ç –±–∏–∑–Ω–µ—Å-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö
‚Ä¢ –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç —Ç—Ä–µ–Ω–¥—ã –∏ –∞–Ω–æ–º–∞–ª–∏–∏
‚Ä¢ –§–æ—Ä–º–∏—Ä—É–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑—ã

*–¢–†–ï–ë–û–í–ê–ù–ò–Ø –î–õ–Ø GPT:*
1. OpenAI API –∫–ª—é—á –≤ .env —Ñ–∞–π–ª–µ:
   OPENAI_API_KEY=sk-–≤–∞—à_–∫–ª—é—á
2. –ê–∫—Ç–∏–≤–Ω–∞—è –ø–æ–¥–ø–∏—Å–∫–∞ OpenAI
3. –ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ

*–ü–û–î–î–ï–†–ñ–ò–í–ê–ï–ú–´–ï –§–û–†–ú–ê–¢–´:*
‚Ä¢ CSV (—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –æ—Ç—á–µ—Ç—ã, –ø—Ä–æ–¥–∞–∂–∏)
‚Ä¢ Excel (–±—é–¥–∂–µ—Ç—ã, –∞–Ω–∞–ª–∏—Ç–∏–∫–∞)
‚Ä¢ JSON (—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)

*–ü–†–ò–ú–ï–† –§–ê–ô–õ–ê –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:*
–ú–µ—Å—è—Ü,–í—ã—Ä—É—á–∫–∞,–†–∞—Å—Ö–æ–¥—ã,–ü—Ä–∏–±—ã–ª—å,–ö–ª–∏–µ–Ω—Ç—ã
–Ø–Ω–≤–∞—Ä—å 2024,1000000,700000,300000,150
–§–µ–≤—Ä–∞–ª—å 2024,1200000,800000,400000,180
–ú–∞—Ä—Ç 2024,1500000,900000,600000,220

*–ü–û–î–î–ï–†–ñ–ö–ê:* @alex_lyubovenko

*–ö–æ–º–∞–Ω–¥—ã:*
/start - –ó–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞
/help - –ü–æ–º–æ—â—å
/cancel - –û—Ç–º–µ–Ω–∏—Ç—å —Ç–µ–∫—É—â—É—é –æ–ø–µ—Ä–∞—Ü–∏—é
/stats - –í–∞—à–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        """

        await update.message.reply_text(
            help_text,
            reply_markup=get_main_menu(),
            parse_mode='Markdown'
        )

    async def cancel_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ö–æ–º–∞–Ω–¥–∞ /cancel - –æ—Ç–º–µ–Ω–∞ —Ç–µ–∫—É—â–µ–π –æ–ø–µ—Ä–∞—Ü–∏–∏"""
        user_id = update.effective_user.id

        if user_id in self.user_data:
            # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            self.user_data.pop(user_id, None)

        await update.message.reply_text(
            "‚úÖ –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞. –í—Å–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —É–¥–∞–ª–µ–Ω—ã.",
            reply_markup=get_main_menu()
        )

    async def stats_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ö–æ–º–∞–Ω–¥–∞ /stats - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        user_id = update.effective_user.id
        stats = self.db.get_user_stats(user_id)

        stats_text = f"""
*–í–ê–®–ê –°–¢–ê–¢–ò–°–¢–ò–ö–ê*

*–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:*
‚Ä¢ –í—Å–µ–≥–æ –∞–Ω–∞–ª–∏–∑–æ–≤: {stats['total_analyses']}
‚Ä¢ GPT –∞–Ω–∞–ª–∏–∑–æ–≤: {stats['gpt_analyses']}
‚Ä¢ –ü–æ—Å–ª–µ–¥–Ω–∏–π –∞–Ω–∞–ª–∏–∑: {stats['last_analysis'] or '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}

*–õ–∏–º–∏—Ç—ã:*
‚Ä¢ GPT –∑–∞–ø—Ä–æ—Å–æ–≤ —Å–µ–≥–æ–¥–Ω—è: {self.db.check_rate_limit(user_id)[0]}/{self.MAX_GPT_REQUESTS_PER_DAY}
‚Ä¢ –õ–∏–º–∏—Ç –Ω–∞ –¥–µ–Ω—å: {self.MAX_GPT_REQUESTS_PER_DAY}
‚Ä¢ –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏: {self.GPT_COOLDOWN_SECONDS} —Å–µ–∫.

*–°–æ–≤–µ—Ç:* –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ø–æ–ª–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.
        """

        await update.message.reply_text(
            stats_text,
            reply_markup=get_main_menu(),
            parse_mode='Markdown'
        )

    async def admin_stats_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ö–æ–º–∞–Ω–¥–∞ /admin_stats - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
        user_id = update.effective_user.id

        if user_id != ADMIN_ID:
            await update.message.reply_text("‚ùå –≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞.")
            return

        stats = self.db.get_admin_stats()

        stats_text = f"""
*–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–î–ú–ò–ù–ò–°–¢–†–ê–¢–û–†–ê*

*–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏:*
‚Ä¢ –í—Å–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {stats['total_users']}
‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ã—Ö (7 –¥–Ω–µ–π): {stats['active_users']}

*–ê–Ω–∞–ª–∏–∑—ã:*
‚Ä¢ –í—Å–µ–≥–æ –∞–Ω–∞–ª–∏–∑–æ–≤: {stats['total_analyses']}
‚Ä¢ GPT –∞–Ω–∞–ª–∏–∑–æ–≤: {stats['total_gpt_analyses']}

*–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π:*
"""

        for day_stat in stats['daily_stats'][:5]:
            stats_text += f"‚Ä¢ {day_stat['date']}: {day_stat['daily_count']} –∞–Ω–∞–ª–∏–∑–æ–≤\n"

        stats_text += "\n*–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ.*"

        await update.message.reply_text(
            stats_text,
            parse_mode='Markdown'
        )

    async def notify_admin(self, message: str, context: ContextTypes.DEFAULT_TYPE):
        """–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –æ –≤–∞–∂–Ω—ã—Ö —Å–æ–±—ã—Ç–∏—è—Ö"""
        if ADMIN_ID:
            try:
                await self.safe_send_message(
                    chat_id=ADMIN_ID,
                    text=f"*–£–í–ï–î–û–ú–õ–ï–ù–ò–ï –ë–û–¢–ê*\n\n{message}",
                    parse_mode='Markdown',
                    context=context
                )
            except Exception as e:
                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–¥–º–∏–Ω—É: {e}")

    # ========== –û–ë–†–ê–ë–û–¢–ö–ê –°–û–û–ë–©–ï–ù–ò–ô ==========
    async def handle_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
        text = update.message.text
        user_id = update.effective_user.id

        logger.info(f"[{user_id}] –ö–Ω–æ–ø–∫–∞: {text}")

        if text == "üìä –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞":
            await update.message.reply_text(
                "*–ó–ê–ì–†–£–ó–ò–¢–ï –§–ê–ô–õ –î–õ–Ø GPT –ê–ù–ê–õ–ò–ó–ê*\n\n"
                "*–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ:*\n"
                "‚Ä¢ –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –æ—Ç—á–µ—Ç—ã\n"
                "‚Ä¢ –î–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö\n"
                "‚Ä¢ –ë—é–¥–∂–µ—Ç—ã –∏ —Ä–∞—Å—Ö–æ–¥—ã\n"
                "‚Ä¢ –ú–µ—Ç—Ä–∏–∫–∏ –±–∏–∑–Ω–µ—Å–∞\n\n"
                f"*–§–æ—Ä–º–∞—Ç—ã:* {', '.join(ALLOWED_EXTENSIONS)}\n"
                f"*–ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä:* {MAX_FILE_SIZE / 1024 / 1024:.0f} MB\n\n"
                "*–î–ª—è –ª—É—á—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:*\n"
                "1. –î–æ–±–∞–≤—å—Ç–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏\n"
                "2. –í–∫–ª—é—á–∏—Ç–µ —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏\n"
                "3. –£–±–µ—Ä–∏—Ç–µ –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏",
                parse_mode='Markdown'
            )

        elif text == "ü§ñ GPT –ê–Ω–∞–ª–∏–∑":
            if user_id in self.user_data and 'df' in self.user_data[user_id]:
                await self.perform_gpt_analysis(update, context, user_id)
            else:
                status = "–ì–û–¢–û–í –ö –†–ê–ë–û–¢–ï" if GPT_AVAILABLE else "–¢–†–ï–ë–£–ï–¢ –ù–ê–°–¢–†–û–ô–ö–ò"

                await update.message.reply_text(
                    f"*GPT –ê–ù–ê–õ–ò–ó* {status}\n\n"
                    f"*–°—Ç–∞—Ç—É—Å:* {'–ù–∞—Å—Ç—Ä–æ–µ–Ω' if GPT_AVAILABLE else '–¢—Ä–µ–±—É–µ—Ç—Å—è API –∫–ª—é—á'}\n\n"
                    f"*–ß—Ç–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é:*\n"
                    f"‚Ä¢ –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏\n"
                    f"‚Ä¢ –¢—Ä–µ–Ω–¥—ã –∏ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏\n"
                    f"‚Ä¢ –ê–Ω–æ–º–∞–ª–∏–∏ –∏ —Ä–∏—Å–∫–∏\n"
                    f"‚Ä¢ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏\n"
                    f"‚Ä¢ –ü—Ä–æ–≥–Ω–æ–∑—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö\n\n"
                    f"*–°–Ω–∞—á–∞–ª–∞:* –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —á–µ—Ä–µ–∑ üìä –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞",
                    reply_markup=get_main_menu(),
                    parse_mode='Markdown'
                )

        elif text == "üìà –ì—Ä–∞—Ñ–∏–∫–∏":
            await update.message.reply_text(
                "*–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –í –í–ï–ë-–ò–ù–¢–ï–†–§–ï–ô–°–ï*\n\n"
                "–ü–æ–ª–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –∏ –¥–∞—à–±–æ—Ä–¥—ã –¥–æ—Å—Ç—É–ø–Ω—ã –≤ –≤–µ–±-–≤–µ—Ä—Å–∏–∏:\n\n"
                "streamlit run ui/streamlit_app.py\n\n"
                "*–ß—Ç–æ –¥–æ—Å—Ç—É–ø–Ω–æ –≤ –≤–µ–±-–≤–µ—Ä—Å–∏–∏:*\n"
                "‚Ä¢ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ Plotly\n"
                "‚Ä¢ –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –¥–∞—à–±–æ—Ä–¥—ã\n"
                "‚Ä¢ –¢–µ–ø–ª–æ–≤—ã–µ –∫–∞—Ä—Ç—ã –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π\n"
                "‚Ä¢ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã\n\n"
                "*Telegram –±–æ—Ç —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–º –∞–Ω–∞–ª–∏–∑–µ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö*",
                parse_mode='Markdown'
            )

        elif text == "üìã –û—Ç—á–µ—Ç":
            if user_id in self.user_data and 'df' in self.user_data[user_id]:
                await self.generate_gpt_report(update, context, user_id)
            else:
                await update.message.reply_text(
                    "*–ì–ï–ù–ï–†–ê–¶–ò–Ø GPT –û–¢–ß–ï–¢–ê*\n\n"
                    "–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n\n"
                    "*–ß—Ç–æ –±—É–¥–µ—Ç –≤ –æ—Ç—á–µ—Ç–µ:*\n"
                    "‚Ä¢ –°–≤–æ–¥–∫–∞ –∞–Ω–∞–ª–∏–∑–∞\n"
                    "‚Ä¢ GPT —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n"
                    "‚Ä¢ –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n"
                    "‚Ä¢ –ü–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π\n"
                    "‚Ä¢ –ü—Ä–æ–≥–Ω–æ–∑—ã –∏ —Ä–∏—Å–∫–∏",
                    reply_markup=get_main_menu(),
                    parse_mode='Markdown'
                )

        elif text == "üè¢ AmoCRM":
            await self.show_amocrm_integration(update, context)

        elif text == "üí° –°–æ–≤–µ—Ç—ã":
            await self.show_gpt_tips(update, context)

        elif text == "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏":
            await self.show_gpt_settings(update, context)

        elif text == "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞":
            await self.stats_command(update, context)

        elif text == "‚ùì –ü–æ–º–æ—â—å":
            await self.help_command(update, context)

        elif text == "‚ùå –û—Ç–º–µ–Ω–∞":
            await self.cancel_command(update, context)

        else:
            await update.message.reply_text(
                "ü§î –Ø –Ω–µ –ø–æ–Ω—è–ª –≤–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—é –Ω–∏–∂–µ –∏–ª–∏ –∫–æ–º–∞–Ω–¥—ã /start, /help",
                reply_markup=get_main_menu()
            )

    # ========== –û–ë–†–ê–ë–û–¢–ö–ê –§–ê–ô–õ–û–í ==========
    async def handle_document(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        user_id = update.effective_user.id
        document = update.message.document
        file_name = document.file_name

        logger.info(f"[{user_id}] –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: {file_name} ({document.file_size} bytes)")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        if document.file_size > MAX_FILE_SIZE:
            await update.message.reply_text(
                f"*–§–ê–ô–õ –°–õ–ò–®–ö–û–ú –ë–û–õ–¨–®–û–ô*\n\n"
                f"–§–∞–π–ª: {file_name}\n"
                f"–†–∞–∑–º–µ—Ä: {document.file_size / 1024 / 1024:.2f} MB\n"
                f"–õ–∏–º–∏—Ç: {MAX_FILE_SIZE / 1024 / 1024:.0f} MB\n\n"
                f"*–°–æ–≤–µ—Ç:* –†–∞–∑–¥–µ–ª–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤",
                parse_mode='Markdown'
            )
            return

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ —Ñ–∞–π–ª–∞
        file_ext = file_name.split('.')[-1].lower() if '.' in file_name else ''
        if file_ext not in ALLOWED_EXTENSIONS:
            await update.message.reply_text(
                f"*–ù–ï–ü–û–î–î–ï–†–ñ–ò–í–ê–ï–ú–´–ô –§–û–†–ú–ê–¢*\n\n"
                f"–§–∞–π–ª: {file_name}\n"
                f"–§–æ—Ä–º–∞—Ç: .{file_ext}\n\n"
                f"*–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:* {', '.join(ALLOWED_EXTENSIONS)}",
                parse_mode='Markdown'
            )
            return

        # –°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏
        status_msg = await update.message.reply_text(
            f"*–ó–ê–ì–†–£–ó–ö–ê –§–ê–ô–õ–ê –î–õ–Ø GPT –ê–ù–ê–õ–ò–ó–ê...*\n\n"
            f"{file_name}\n"
            f"–†–∞–∑–º–µ—Ä: {document.file_size / 1024:.0f} KB\n"
            f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –∞–Ω–∞–ª–∏–∑—É...",
            parse_mode='Markdown'
        )

        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        try:
            file = await document.get_file()

            temp_file_path = self.temp_dir / f"upload_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{file_ext}"
            await file.download_to_drive(temp_file_path)

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            df = self.load_dataframe(temp_file_path, file_ext)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ
            if df.empty:
                raise ValueError("–§–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö")

            # –°–æ–∑–¥–∞–µ–º —Ö–µ—à –¥–∞–Ω–Ω—ã—Ö
            data_hash = self.create_data_hash(df)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
            self.user_data[user_id] = {
                'df': df,
                'filename': file_name,
                'file_path': str(temp_file_path),
                'data_hash': data_hash,
                'uploaded_at': datetime.now(),
                'preview': self.get_data_preview(df)
            }

            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            preview = self.user_data[user_id]['preview']

            # –†–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            success = await self.safe_edit_message_text(
                message=status_msg,
                text=f"*–§–ê–ô–õ –ì–û–¢–û–í –ö GPT –ê–ù–ê–õ–ò–ó–£!*\n\n"
                     f"{file_name}\n"
                     f"*{len(df):,}* –∑–∞–ø–∏—Å–µ–π | *{len(df.columns)}* –∫–æ–ª–æ–Ω–æ–∫\n\n"
                     f"{preview}\n\n"
                     f"*–í–´–ë–ï–†–ò–¢–ï –¢–ò–ü –ê–ù–ê–õ–ò–ó–ê:*",
                parse_mode='Markdown',
                reply_markup=get_analysis_menu(),
                context=context
            )

            if not success:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                await self.safe_send_message(
                    chat_id=user_id,
                    text=f"*–§–ê–ô–õ –ì–û–¢–û–í –ö GPT –ê–ù–ê–õ–ò–ó–£!*\n\n"
                         f"{file_name}\n"
                         f"*{len(df):,}* –∑–∞–ø–∏—Å–µ–π | *{len(df.columns)}* –∫–æ–ª–æ–Ω–æ–∫\n\n"
                         f"{preview}\n\n"
                         f"*–í–´–ë–ï–†–ò–¢–ï –¢–ò–ü –ê–ù–ê–õ–ò–ó–ê:*",
                    parse_mode='Markdown',
                    reply_markup=get_analysis_menu(),
                    context=context
                )

            logger.info(f"[{user_id}] –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω: {len(df)} –∑–∞–ø–∏—Å–µ–π, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")

        except Exception as e:
            error_msg = str(e)
            logger.error(f"[{user_id}] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {error_msg}")

            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            try:
                if 'temp_file_path' in locals():
                    os.unlink(temp_file_path)
            except:
                pass

            success = await self.safe_edit_message_text(
                message=status_msg,
                text=f"*–û–®–ò–ë–ö–ê –ó–ê–ì–†–†–£–ó–ö–ò*\n\n"
                     f"–§–∞–π–ª: {file_name}\n\n"
                     f"*–ü—Ä–∏—á–∏–Ω–∞:* {error_msg[:150]}\n\n"
                     f"*–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:*\n"
                     f"1. –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞–Ω–Ω—ã—Ö\n"
                     f"2. –ö–æ–¥–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–∞ (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ UTF-8)\n"
                     f"3. –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –≤ CSV (–∑–∞–ø—è—Ç–∞—è –∏–ª–∏ —Ç–æ—á–∫–∞ —Å –∑–∞–ø—è—Ç–æ–π)",
                parse_mode='Markdown',
                context=context
            )

            if not success:
                await update.message.reply_text(
                    f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {error_msg[:150]}",
                    parse_mode=None
                )

    def load_dataframe(self, file_path, file_ext):
        """–ó–∞–≥—Ä—É–∑–∫–∞ DataFrame —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            if file_ext == 'csv':
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                try:
                    return pd.read_csv(file_path, encoding='utf-8')
                except:
                    return pd.read_csv(file_path, encoding='cp1251')
            elif file_ext in ['xlsx', 'xls']:
                return pd.read_excel(file_path)
            elif file_ext == 'json':
                return pd.read_json(file_path)
            else:
                # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                try:
                    return pd.read_csv(file_path)
                except:
                    try:
                        return pd.read_excel(file_path)
                    except:
                        raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: .{file_ext}")
        except Exception as e:
            raise ValueError(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}")

    def get_data_preview(self, df):
        """–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö"""
        preview = "*–°–¢–†–£–ö–¢–£–†–ê –î–ê–ù–ù–´–•:*\n"

        numeric_cols = df.select_dtypes(include='number').columns
        text_cols = df.select_dtypes(include='object').columns

        preview += f"‚Ä¢ –ß–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {len(numeric_cols)}\n"
        preview += f"‚Ä¢ –¢–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {len(text_cols)}\n"
        preview += f"‚Ä¢ –ü—Ä–æ–ø—É—Å–∫–æ–≤: {df.isnull().sum().sum()}\n"

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫
        if len(df) > 0:
            preview += f"‚Ä¢ –ü–µ—Ä–≤–∞—è –¥–∞—Ç–∞/–≤—Ä–µ–º—è: "
            # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏
            for col in df.columns:
                try:
                    if pd.api.types.is_datetime64_any_dtype(df[col]) or 'date' in col.lower() or 'time' in col.lower():
                        preview += f"{df[col].iloc[0]}\n"
                        break
                except:
                    pass

            if len(numeric_cols) > 0:
                preview += "\n*–ü–ï–†–í–´–ï –ß–ò–°–õ–û–í–´–ï –ö–û–õ–û–ù–ö–ò:*\n"
                for col in numeric_cols[:3]:
                    preview += f"‚Ä¢ {col}: {df[col].dtype}, "
                    preview += f"avg: {df[col].mean():.2f}\n"

        return preview

    # ========== –û–ë–†–ê–ë–û–¢–ö–ê CALLBACK ==========
    async def handle_callback(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ callback –∫–Ω–æ–ø–æ–∫"""
        query = update.callback_query
        await query.answer()

        user_id = update.effective_user.id
        action = query.data

        logger.info(f"[{user_id}] Callback: {action}")

        if action == "quick":
            await self.quick_analysis(query, context, user_id)
        elif action == "gpt":
            await self.gpt_analysis_callback(query, context, user_id)
        elif action == "full_report":
            await self.full_report_callback(query, context, user_id)
        elif action == "recommend":
            await self.show_recommendations(query, context, user_id)
        elif action == "details":
            await self.show_details(query, context, user_id)
        elif action == "viz":
            await self.show_visualization_info(query, context)
        elif action == "my_stats":
            await self.show_my_stats_callback(query, context, user_id)
        elif action == "set_api_key":
            await self.show_api_key_help(query, context)
        elif action == "set_model":
            await self.show_model_settings(query, context)
        elif action == "model_gpt35":
            await self.set_model(query, context, "gpt-3.5-turbo")
        elif action == "model_gpt4":
            await self.set_model(query, context, "gpt-4")
        elif action == "model_gpt4t":
            await self.set_model(query, context, "gpt-4-turbo")
        elif action == "model_gpt4o":
            await self.set_model(query, context, "gpt-4o")
        elif action == "set_context":
            await self.show_context_settings(query, context)
        elif action == "back_to_settings":
            await self.back_to_settings(query, context)
        elif action == "back_to_main":
            await self.back_to_main(query, context)
        elif action == "cancel_operation":
            await self.cancel_operation(query, context, user_id)
        else:
            await self.safe_edit_callback_message(
                query=query,
                text="ü§î –î–µ–π—Å—Ç–≤–∏–µ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ",
                reply_markup=get_main_menu()
            )

    async def quick_analysis(self, query, context, user_id):
        """–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑"""
        if user_id not in self.user_data:
            await self.safe_edit_callback_message(
                query=query,
                text="‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞",
                parse_mode=None
            )
            return

        data = self.user_data[user_id]
        df = data['df']
        filename = data['filename']

        await self.safe_edit_callback_message(
            query=query,
            text="*–í–´–ü–û–õ–ù–Ø–Æ –ë–´–°–¢–†–´–ô –ê–ù–ê–õ–ò–ó...*",
            parse_mode='Markdown'
        )

        try:
            # –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
            basic_analysis = self.analyzer.basic_analysis(df)

            response = f"*–ë–´–°–¢–†–´–ô –ê–ù–ê–õ–ò–ó: {filename}*\n\n"
            response += f"*–û–°–ù–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò:*\n"
            response += f"‚Ä¢ –ó–∞–ø–∏—Å–µ–π: {len(df):,}\n"
            response += f"‚Ä¢ –ö–æ–ª–æ–Ω–æ–∫: {len(df.columns)}\n"

            if 'record_count' in basic_analysis:
                response += f"‚Ä¢ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {basic_analysis['record_count']}\n"

            if 'summary' in basic_analysis:
                summary = basic_analysis['summary'][:300]
                response += f"\n*–°–í–û–î–ö–ê:*\n{summary}...\n"

            numeric_cols = df.select_dtypes(include='number').columns
            if len(numeric_cols) > 0:
                response += f"\n*–§–ò–ù–ê–ù–°–û–í–´–ï –ü–û–ö–ê–ó–ê–¢–ï–õ–ò:*\n"
                for col in numeric_cols[:3]:
                    if df[col].dtype in ['int64', 'float64']:
                        response += f"‚Ä¢ {col}:\n"
                        response += f"  –°—Ä–µ–¥–Ω–µ–µ: {df[col].mean():,.2f}\n"
                        response += f"  –°—É–º–º–∞: {df[col].sum():,.2f}\n"
                        response += f"  –î–∏–∞–ø–∞–∑–æ–Ω: {df[col].min():.2f} - {df[col].max():.2f}\n\n"

            response += "*–î–õ–Ø –ü–û–î–†–û–ë–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê:*\n"
            response += "–ù–∞–∂–º–∏—Ç–µ ü§ñ GPT –ê–Ω–∞–ª–∏–∑"

            await self.safe_edit_callback_message(
                query=query,
                text=response,
                parse_mode='Markdown',
                reply_markup=get_analysis_menu()
            )

            # –õ–æ–≥–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ –≤ –ë–î
            self.db.log_analysis(
                user_id=user_id,
                filename=filename,
                file_hash=data['data_hash'],
                record_count=len(df),
                columns_count=len(df.columns),
                analysis_type='quick'
            )

        except Exception as e:
            logger.error(f"[{user_id}] –û—à–∏–±–∫–∞ –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            error_msg = str(e)[:200] if len(str(e)) > 200 else str(e)
            await self.safe_edit_callback_message(
                query=query,
                text=f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {error_msg}",
                parse_mode=None,
                reply_markup=get_analysis_menu()
            )

    async def gpt_analysis_callback(self, query, context, user_id):
        """GPT –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ callback"""
        if user_id not in self.user_data:
            await self.safe_edit_callback_message(
                query=query,
                text="‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞",
                parse_mode=None
            )
            return

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º rate limit
        allowed, error_message = await self.check_gpt_rate_limit(user_id)
        if not allowed:
            await self.safe_edit_callback_message(
                query=query,
                text=f"‚ùå *–õ–∏–º–∏—Ç –ø—Ä–µ–≤—ã—à–µ–Ω*\n\n{error_message}",
                parse_mode='Markdown',
                reply_markup=get_analysis_menu()
            )
            return

        data = self.user_data[user_id]
        df = data['df']
        filename = data['filename']

        await self.safe_edit_callback_message(
            query=query,
            text="*–ó–ê–ü–£–°–ö–ê–Æ GPT –ê–ù–ê–õ–ò–ó...*\n\n"
                 "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ.\n"
                 "‚è≥ –≠—Ç–æ –∑–∞–π–º–µ—Ç 10-30 —Å–µ–∫—É–Ω–¥...",
            parse_mode='Markdown'
        )

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            cached_result = self.get_cached_analysis(data['data_hash'], 'gpt')
            if cached_result:
                response = cached_result
                logger.info(f"[{user_id}] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π GPT –∞–Ω–∞–ª–∏–∑")
            else:
                # –í—ã–ø–æ–ª–Ω—è–µ–º GPT –∞–Ω–∞–ª–∏–∑
                gpt_result = self.analyzer.gpt_analysis(df)
                response = self.format_gpt_response(gpt_result, filename)

            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏ –µ—Å–ª–∏ –¥–ª–∏–Ω–Ω—ã–π
            MESSAGE_LIMIT = 3500  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ª–∏–º–∏—Ç –¥–ª—è Telegram
            if len(response) > MESSAGE_LIMIT:
                parts = self.split_long_message(response, MESSAGE_LIMIT)
                for i, part in enumerate(parts):
                    if i == 0:
                        await self.safe_edit_callback_message(
                            query=query,
                            text=part,
                            parse_mode='Markdown',
                            reply_markup=get_analysis_menu() if i == len(parts) - 1 else None
                        )
                    else:
                        await self.safe_send_message(
                            chat_id=user_id,
                            text=part,
                            parse_mode='Markdown',
                            context=context
                        )
            else:
                await self.safe_edit_callback_message(
                    query=query,
                    text=response,
                    parse_mode='Markdown',
                    reply_markup=get_analysis_menu()
                )

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ GPT –∑–∞–ø—Ä–æ—Å–æ–≤
            self.db.increment_gpt_requests(user_id)

            # –õ–æ–≥–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ –≤ –ë–î
            self.db.log_analysis(
                user_id=user_id,
                filename=filename,
                file_hash=data['data_hash'],
                record_count=len(df),
                columns_count=len(df.columns),
                analysis_type='gpt',
                gpt_used=True
            )

            logger.info(f"[{user_id}] GPT –∞–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")

        except Exception as e:
            error_msg = str(e)
            logger.error(f"[{user_id}] –û—à–∏–±–∫–∞ GPT –∞–Ω–∞–ª–∏–∑–∞: {error_msg}")

            if "API" in error_msg or "key" in error_msg.lower() or "openai" in error_msg.lower():
                error_display = """
‚ùå *–û–®–ò–ë–ö–ê GPT –ê–ù–ê–õ–ò–ó–ê*

*–ü—Ä–∏—á–∏–Ω–∞:* –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω OpenAI API –∫–ª—é—á

*–ö–ê–ö –ò–°–ü–†–ê–í–ò–¢–¨:*
1. –ü–æ–ª—É—á–∏—Ç–µ API –∫–ª—é—á –Ω–∞ platform.openai.com
2. –î–æ–±–∞–≤—å—Ç–µ –≤ —Ñ–∞–π–ª `.env`:
   OPENAI_API_KEY=sk-–≤–∞—à_–∫–ª—é—á_–∑–¥–µ—Å—å
3. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –±–æ—Ç–∞

*–ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ê:*
–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º GPT –∞–Ω–∞–ª–∏–∑–æ–º
                """
            else:
                error_display = f"‚ùå *–û–®–ò–ë–ö–ê GPT –ê–ù–ê–õ–ò–ó–ê:*\n\n{error_msg[:300]}"

            await self.safe_edit_callback_message(
                query=query,
                text=error_display,
                parse_mode='Markdown',
                reply_markup=get_analysis_menu()
            )

    def format_gpt_response(self, gpt_result, filename):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GPT –æ—Ç–≤–µ—Ç–∞"""
        response = f"*GPT –ê–ù–ê–õ–ò–ó: {filename}*\n\n"
        response += "=" * 40 + "\n\n"

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç GPT –∞–Ω–∞–ª–∏–∑–∞
        response += gpt_result

        response += "\n" + "=" * 40 + "\n\n"
        response += "*–ö–õ–Æ–ß–ï–í–´–ï –í–´–í–û–î–´:*\n\n"

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations = [
            "*–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å* –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏",
            "*–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–π—Ç–µ —Å AmoCRM* –¥–ª—è –ø–æ–ª–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏",
            "*–ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –æ—Ç—á–µ—Ç—ã* –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞",
            "*–í–∫–ª—é—á–∏—Ç–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑* –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö"
        ]

        for rec in recommendations:
            response += f"‚Ä¢ {rec}\n"

        response += "\n*–î–õ–Ø –£–ì–õ–£–ë–õ–ï–ù–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê:*\n"
        response += "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (2+ –≥–æ–¥–∞)\n"
        response += "2. –î–æ–±–∞–≤—å—Ç–µ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –∫–ª–∏–µ–Ω—Ç–æ–≤\n"
        response += "3. –í–∫–ª—é—á–∏—Ç–µ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n"
        response += "4. –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–π—Ç–µ —Å CRM —Å–∏—Å—Ç–µ–º–æ–π"

        return response

    def split_long_message(self, text, max_length=3500):
        """–†–∞–∑–±–∏–≤–∫–∞ –¥–ª–∏–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ —á–∞—Å—Ç–∏"""
        parts = []
        while len(text) > max_length:
            # –ò—â–µ–º —Ö–æ—Ä–æ—à–µ–µ –º–µ—Å—Ç–æ –¥–ª—è —Ä–∞–∑—Ä—ã–≤–∞
            split_pos = text.rfind('\n\n', 0, max_length)
            if split_pos == -1:
                split_pos = text.rfind('\n', 0, max_length)
            if split_pos == -1:
                split_pos = max_length
            parts.append(text[:split_pos])
            text = text[split_pos:].lstrip()
        parts.append(text)
        return parts

    async def full_report_callback(self, query, context, user_id):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ —á–µ—Ä–µ–∑ callback"""
        if user_id not in self.user_data:
            await self.safe_edit_callback_message(
                query=query,
                text="‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç—á–µ—Ç–∞",
                parse_mode=None
            )
            return

        data = self.user_data[user_id]
        df = data['df']
        filename = data['filename']

        await self.safe_edit_callback_message(
            query=query,
            text="*–°–û–ó–î–ê–Æ GPT –û–¢–ß–ï–¢...*\n\n"
                 "–ì–µ–Ω–µ—Ä–∏—Ä—É—é –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å –∞–Ω–∞–ª–∏–∑–æ–º...",
            parse_mode='Markdown'
        )

        temp_path = None
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –¥–ª—è –æ—Ç—á–µ—Ç–∞
            basic_analysis = self.analyzer.basic_analysis(df)
            gpt_analysis = self.analyzer.gpt_analysis(
                df) if GPT_AVAILABLE else "GPT –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ API –∫–ª—é—á."

            # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
            report = self.create_gpt_report(df, filename, basic_analysis, gpt_analysis)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            temp_path = self.temp_dir / f"report_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            with open(temp_path, 'w', encoding='utf-8') as f:
                f.write(report)

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª
            await context.bot.send_document(
                chat_id=user_id,
                document=open(temp_path, 'rb'),
                filename=f"GPT_Report_{filename.replace('.', '_')}.md",
                caption=f"*GPT –û–¢–ß–ï–¢: {filename}*\n\n–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Ç AI Business Auditor",
                parse_mode='Markdown',
                reply_markup=get_main_menu()
            )

            await self.safe_edit_callback_message(
                query=query,
                text="‚úÖ *GPT –û–¢–ß–ï–¢ –°–û–ó–î–ê–ù!*\n\n"
                     "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª –≤ —á–∞—Ç–µ üìé",
                parse_mode='Markdown',
                reply_markup=get_main_menu()
            )

            # –õ–æ–≥–∏—Ä—É–µ–º –≤ –ë–î
            self.db.log_analysis(
                user_id=user_id,
                filename=filename,
                file_hash=data['data_hash'],
                record_count=len(df),
                columns_count=len(df.columns),
                analysis_type='full_report'
            )

            logger.info(f"[{user_id}] –û—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {temp_path}")

        except Exception as e:
            logger.error(f"[{user_id}] –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")
            await self.safe_edit_callback_message(
                query=query,
                text=f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {str(e)[:100]}",
                parse_mode=None,
                reply_markup=get_main_menu()
            )
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            try:
                if temp_path and os.path.exists(temp_path):
                    os.unlink(temp_path)
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {e}")

    def create_gpt_report(self, df, filename, basic_analysis, gpt_analysis):
        """–°–æ–∑–¥–∞–Ω–∏–µ GPT –æ—Ç—á–µ—Ç–∞"""
        report = f"# üìä GPT –û–¢–ß–ï–¢: {filename}\n\n"
        report += f"*–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞:* {datetime.now().strftime('%Y-%m-%d %H:%M')}\n"
        report += f"*–ó–∞–ø–∏—Å–µ–π:* {len(df):,}\n"
        report += f"*–ö–æ–ª–æ–Ω–æ–∫:* {len(df.columns)}\n\n"

        report += "## üìà –û–ë–©–ê–Ø –°–í–û–î–ö–ê\n\n"
        if 'summary' in basic_analysis:
            report += f"{basic_analysis['summary']}\n\n"

        report += "## ü§ñ GPT –ê–ù–ê–õ–ò–ó\n\n"
        report += f"{gpt_analysis}\n\n"

        report += "## üìä –ö–õ–Æ–ß–ï–í–´–ï –ú–ï–¢–†–ò–ö–ò\n\n"
        numeric_cols = df.select_dtypes(include='number').columns
        if len(numeric_cols) > 0:
            report += "| –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å | –°—Ä–µ–¥–Ω–µ–µ | –°—É–º–º–∞ | –ú–∏–Ω | –ú–∞–∫—Å |\n"
            report += "|------------|---------|-------|-----|------|\n"
            for col in numeric_cols[:5]:
                report += f"| {col} | {df[col].mean():.2f} | {df[col].sum():.2f} | {df[col].min():.2f} | {df[col].max():.2f} |\n"
            report += "\n"

        report += "## üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò\n\n"
        recommendations = [
            "1. **–í–Ω–µ–¥—Ä–∏—Ç–µ —Å–∏—Å—Ç–µ–º—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞** –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫",
            "2. **–ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –æ—Ç—á–µ—Ç—ã** –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –¥–∏–Ω–∞–º–∏–∫–∏",
            "3. **–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–π—Ç–µ –¥–∞–Ω–Ω—ã–µ** —Å CRM —Å–∏—Å—Ç–µ–º–æ–π (AmoCRM)",
            "4. **–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–π—Ç–µ —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö** –¥–ª—è –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞",
            "5. **–í–Ω–µ–¥—Ä–∏—Ç–µ –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É** –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"
        ]

        for rec in recommendations:
            report += f"{rec}\n"

        report += "\n## üéØ –ü–õ–ê–ù –î–ï–ô–°–¢–í–ò–ô\n\n"
        report += "### –ù–µ–¥–µ–ª—è 1-2:\n"
        report += "- [ ] –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç—á–µ—Ç–æ–≤\n"
        report += "- [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å AmoCRM\n"
        report += "- [ ] –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ KPI\n\n"

        report += "### –ù–µ–¥–µ–ª—è 3-4:\n"
        report += "- [ ] –í–Ω–µ–¥—Ä–µ–Ω–∏–µ –¥–∞—à–±–æ—Ä–¥–æ–≤\n"
        report += "- [ ] –û–±—É—á–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã\n"
        report += "- [ ] –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤\n\n"

        report += "---\n"
        report += "*–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ AI Business Auditor —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPT*\n"
        report += "*–î–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å*"

        return report

    async def perform_gpt_analysis(self, update, context, user_id):
        """GPT –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ —Å–æ–æ–±—â–µ–Ω–∏–µ"""
        if user_id not in self.user_data:
            await update.message.reply_text("‚ùå –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª")
            return

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º rate limit
        allowed, error_message = await self.check_gpt_rate_limit(user_id)
        if not allowed:
            await update.message.reply_text(
                f"‚ùå *–õ–∏–º–∏—Ç –ø—Ä–µ–≤—ã—à–µ–Ω*\n\n{error_message}",
                parse_mode='Markdown'
            )
            return

        data = self.user_data[user_id]
        df = data['df']
        filename = data['filename']

        status_msg = await update.message.reply_text(
            "*–ó–ê–ü–£–°–ö–ê–Æ GPT –ê–ù–ê–õ–ò–ó...*\n\n"
            "AI –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ...",
            parse_mode='Markdown'
        )

        try:
            gpt_result = self.analyzer.gpt_analysis(df)
            response = self.format_gpt_response(gpt_result, filename)

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —á–∞—Å—Ç—è–º–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            MESSAGE_LIMIT = 3500
            if len(response) > MESSAGE_LIMIT:
                parts = self.split_long_message(response, MESSAGE_LIMIT)
                for i, part in enumerate(parts):
                    if i == 0:
                        success = await self.safe_edit_message_text(
                            message=status_msg,
                            text=part,
                            parse_mode='Markdown',
                            context=context
                        )
                        if not success:
                            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                            await self.safe_send_message(
                                chat_id=user_id,
                                text=part,
                                parse_mode='Markdown',
                                context=context
                            )
                    else:
                        await self.safe_send_message(
                            chat_id=user_id,
                            text=part,
                            parse_mode='Markdown',
                            context=context
                        )
            else:
                success = await self.safe_edit_message_text(
                    message=status_msg,
                    text=response,
                    parse_mode='Markdown',
                    reply_markup=get_main_menu(),
                    context=context
                )

                if not success:
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                    await self.safe_send_message(
                        chat_id=user_id,
                        text=response,
                        parse_mode='Markdown',
                        reply_markup=get_main_menu(),
                        context=context
                    )

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ GPT –∑–∞–ø—Ä–æ—Å–æ–≤
            self.db.increment_gpt_requests(user_id)

            # –õ–æ–≥–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ –≤ –ë–î
            self.db.log_analysis(
                user_id=user_id,
                filename=filename,
                file_hash=data['data_hash'],
                record_count=len(df),
                columns_count=len(df.columns),
                analysis_type='gpt',
                gpt_used=True
            )

        except Exception as e:
            logger.error(f"[{user_id}] –û—à–∏–±–∫–∞ GPT –∞–Ω–∞–ª–∏–∑–∞ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏: {e}")
            error_msg = str(e)[:200] if len(str(e)) > 200 else str(e)

            success = await self.safe_edit_message_text(
                message=status_msg,
                text=f"‚ùå –û—à–∏–±–∫–∞ GPT –∞–Ω–∞–ª–∏–∑–∞: {error_msg}",
                parse_mode=None,
                reply_markup=get_main_menu(),
                context=context
            )

            if not success:
                await update.message.reply_text(
                    f"‚ùå –û—à–∏–±–∫–∞ GPT –∞–Ω–∞–ª–∏–∑–∞: {error_msg}",
                    reply_markup=get_main_menu()
                )

    async def generate_gpt_report(self, update, context, user_id):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ —á–µ—Ä–µ–∑ —Å–æ–æ–±—â–µ–Ω–∏–µ"""
        if user_id not in self.user_data:
            await update.message.reply_text("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç—á–µ—Ç–∞")
            return

        data = self.user_data[user_id]
        df = data['df']
        filename = data['filename']

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π –æ—Ç—á–µ—Ç
        report = f"# –û—Ç—á–µ—Ç: {filename}\n\n"
        report += f"–î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d')}\n\n"
        report += f"üìä –ó–∞–ø–∏—Å–µ–π: {len(df):,}\n"
        report += f"üìã –ö–æ–ª–æ–Ω–æ–∫: {len(df.columns)}\n\n"

        numeric_cols = df.select_dtypes(include='number').columns
        if len(numeric_cols) > 0:
            report += "üìà **–û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏:**\n\n"
            for col in numeric_cols[:3]:
                report += f"**{col}:**\n"
                report += f"- –°—Ä–µ–¥–Ω–µ–µ: {df[col].mean():.2f}\n"
                report += f"- –°—É–º–º–∞: {df[col].sum():.2f}\n"
                report += f"- –ú–∏–Ω/–ú–∞–∫—Å: {df[col].min():.2f} / {df[col].max():.2f}\n\n"

        report += "üí° *–î–ª—è –ø–æ–ª–Ω–æ–≥–æ GPT –æ—Ç—á–µ—Ç–∞:*\n"
        report += "1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å\n"
        report += "2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ OpenAI API –∫–ª—é—á\n"
        report += "3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –º–µ–Ω—é –±–æ—Ç–∞"

        temp_path = None
        try:
            temp_path = self.temp_dir / f"simple_report_{user_id}_{datetime.now().strftime('%H%M%S')}.md"
            with open(temp_path, 'w', encoding='utf-8') as f:
                f.write(report)

            await context.bot.send_document(
                chat_id=user_id,
                document=open(temp_path, 'rb'),
                filename=f"simple_report_{filename.replace('.', '_')}.md",
                caption="üìã –ë—ã—Å—Ç—Ä—ã–π –æ—Ç—á–µ—Ç –ø–æ –≤–∞—à–∏–º –¥–∞–Ω–Ω—ã–º",
                reply_markup=get_main_menu()
            )

            # –õ–æ–≥–∏—Ä—É–µ–º –≤ –ë–î
            self.db.log_analysis(
                user_id=user_id,
                filename=filename,
                file_hash=data['data_hash'],
                record_count=len(df),
                columns_count=len(df.columns),
                analysis_type='simple_report'
            )

        except Exception as e:
            logger.error(f"[{user_id}] –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {e}")
            await update.message.reply_text(
                f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {str(e)[:100]}",
                reply_markup=get_main_menu()
            )
        finally:
            try:
                if temp_path and os.path.exists(temp_path):
                    os.unlink(temp_path)
            except:
                pass

    async def show_recommendations(self, query, context, user_id):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        if user_id not in self.user_data:
            await self.safe_edit_callback_message(
                query=query,
                text="‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π",
                parse_mode=None
            )
            return

        data = self.user_data[user_id]
        df = data['df']

        recommendations = [
            "*–°–û–ë–ò–†–ê–ô–¢–ï –ë–û–õ–¨–®–ï –î–ê–ù–ù–´–•:* –ß–µ–º –±–æ–ª—å—à–µ –∏—Å—Ç–æ—Ä–∏—è, —Ç–µ–º —Ç–æ—á–Ω–µ–µ –∞–Ω–∞–ª–∏–∑",
            "*–ò–ù–¢–ï–ì–†–ò–†–£–ô–¢–ï –° CRM:* –û–±—ä–µ–¥–∏–Ω–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –∏ –∫–ª–∏–µ–Ω—Ç–∞—Ö",
            "*–ê–í–¢–û–ú–ê–¢–ò–ó–ò–†–£–ô–¢–ï –û–¢–ß–ï–¢–´:* –ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Ä–µ–≥—É–ª—è—Ä–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é",
            "*–ò–°–ü–û–õ–¨–ó–£–ô–¢–ï GPT –ê–ù–ê–õ–ò–ó:* –ü–æ–ª—É—á–∞–π—Ç–µ AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏",
            "*–û–ü–†–ï–î–ï–õ–ò–¢–ï KPI:* –ß–µ—Ç–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"
        ]

        response = "*–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –í–ê–®–ò–• –î–ê–ù–ù–´–•*\n\n"
        response += f"–ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ {len(df)} –∑–∞–ø–∏—Å–µ–π:\n\n"

        for i, rec in enumerate(recommendations[:4], 1):
            response += f"{i}. {rec}\n"

        response += "\n*–°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:*\n"
        response += "1. –ù–∞–∂–º–∏—Ç–µ ü§ñ GPT –ê–Ω–∞–ª–∏–∑\n"
        response += "2. –°–æ–∑–¥–∞–π—Ç–µ –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç\n"
        response += "3. –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–π—Ç–µ —Å AmoCRM"

        await self.safe_edit_callback_message(
            query=query,
            text=response,
            parse_mode='Markdown',
            reply_markup=get_analysis_menu()
        )

    async def show_details(self, query, context, user_id):
        """–ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª–∏ –¥–∞–Ω–Ω—ã—Ö"""
        if user_id not in self.user_data:
            await self.safe_edit_callback_message(
                query=query,
                text="‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                parse_mode=None
            )
            return

        data = self.user_data[user_id]
        df = data['df']
        filename = data['filename']

        response = f"*–î–ï–¢–ê–õ–ò –î–ê–ù–ù–´–•: {filename}*\n\n"

        response += "*–°–¢–†–£–ö–¢–£–†–ê:*\n"
        response += f"‚Ä¢ –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:\n"

        for col in df.columns[:5]:
            dtype = str(df[col].dtype)
            response += f"  {col}: {dtype}\n"

        if len(df.columns) > 5:
            response += f"  ... –∏ –µ—â–µ {len(df.columns) - 5} –∫–æ–ª–æ–Ω–æ–∫\n"

        response += f"\n*–†–ê–ó–ú–ï–†:* {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\n"
        response += f"*–ü–†–û–ü–£–°–ö–ò:* {df.isnull().sum().sum()}\n"

        numeric_cols = df.select_dtypes(include='number').columns
        if len(numeric_cols) > 0:
            response += f"\n*–ß–ò–°–õ–û–í–´–ï –ü–û–ö–ê–ó–ê–¢–ï–õ–ò:* {len(numeric_cols)} –∫–æ–ª–æ–Ω–æ–∫\n"

        await self.safe_edit_callback_message(
            query=query,
            text=response,
            parse_mode='Markdown',
            reply_markup=get_analysis_menu()
        )

    async def show_visualization_info(self, query, context):
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
        response = "*–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –î–ê–ù–ù–´–•*\n\n"
        response += "–ü–æ–ª–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –≤ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ:\n\n"
        response += "streamlit run ui/streamlit_app.py\n\n"
        response += "*–î–æ—Å—Ç—É–ø–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏:*\n"
        response += "‚Ä¢ –õ–∏–Ω–µ–π–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ —Ç—Ä–µ–Ω–¥–æ–≤\n"
        response += "‚Ä¢ –°—Ç–æ–ª–±—á–∞—Ç—ã–µ –¥–∏–∞–≥—Ä–∞–º–º—ã\n"
        response += "‚Ä¢ –¢–æ—á–µ—á–Ω—ã–µ –¥–∏–∞–≥—Ä–∞–º–º—ã –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π\n"
        response += "‚Ä¢ –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π\n"
        response += "‚Ä¢ Heatmaps –≤–∑–∞–∏–º–æ—Å–≤—è–∑–µ–π\n\n"
        response += "Telegram –±–æ—Ç —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∞–Ω–∞–ª–∏–∑–∞—Ö –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö."

        await self.safe_edit_callback_message(
            query=query,
            text=response,
            parse_mode='Markdown',
            reply_markup=get_analysis_menu()
        )

    async def show_my_stats_callback(self, query, context, user_id):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ callback"""
        stats = self.db.get_user_stats(user_id)

        requests_today, last_request, reset_date = self.db.check_rate_limit(user_id)

        stats_text = f"""
*–í–ê–®–ê –°–¢–ê–¢–ò–°–¢–ò–ö–ê*

*–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:*
‚Ä¢ –í—Å–µ–≥–æ –∞–Ω–∞–ª–∏–∑–æ–≤: {stats['total_analyses']}
‚Ä¢ GPT –∞–Ω–∞–ª–∏–∑–æ–≤: {stats['gpt_analyses']}
‚Ä¢ –ü–æ—Å–ª–µ–¥–Ω–∏–π –∞–Ω–∞–ª–∏–∑: {stats['last_analysis'] or '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}

*–¢–µ–∫—É—â–∏–µ –ª–∏–º–∏—Ç—ã:*
‚Ä¢ GPT –∑–∞–ø—Ä–æ—Å–æ–≤ —Å–µ–≥–æ–¥–Ω—è: {requests_today}/{self.MAX_GPT_REQUESTS_PER_DAY}
‚Ä¢ –°–±—Ä–æ—Å –ª–∏–º–∏—Ç–∞: {reset_date}

*–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:*
1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ø–æ–ª–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
2. –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ –∞–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é GPT
3. –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–π—Ç–µ —Å AmoCRM
        """

        await self.safe_edit_callback_message(
            query=query,
            text=stats_text,
            parse_mode='Markdown',
            reply_markup=get_analysis_menu()
        )

    async def show_amocrm_integration(self, update, context):
        """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å AmoCRM"""
        response = """
*AMOCRM –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø*

*–î–û–°–¢–£–ü–ù–´–ï –í–û–ó–ú–û–ñ–ù–û–°–¢–ò:*
‚Ä¢ –ê–Ω–∞–ª–∏–∑ —Å–¥–µ–ª–æ–∫ –∏ –≤–æ—Ä–æ–Ω–æ–∫
‚Ä¢ –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤
‚Ä¢ –ü—Ä–æ–≥–Ω–æ–∑ –≤—ã—Ä—É—á–∫–∏
‚Ä¢ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤

*–ö–ê–ö –ù–ê–°–¢–†–û–ò–¢–¨:*
1. –°–æ–∑–¥–∞–π—Ç–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –≤ AmoCRM
2. –ü–æ–ª—É—á–∏—Ç–µ access_token
3. –î–æ–±–∞–≤—å—Ç–µ –≤ .env —Ñ–∞–π–ª:
   AMOCRM_ACCESS_TOKEN=–≤–∞—à_—Ç–æ–∫–µ–Ω
   AMOCRM_SUBDOMAIN=–≤–∞—à_–¥–æ–º–µ–Ω
4. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –±–æ—Ç–∞

*–î–ï–ú–û-–†–ï–ñ–ò–ú:* –£–∂–µ –¥–æ—Å—Ç—É–ø–µ–Ω –≤ –±–æ—Ç–µ
*–ü–û–õ–ù–ê–Ø –í–ï–†–°–ò–Ø:* –í –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ
        """

        await self.safe_send_message(
            chat_id=update.effective_chat.id,
            text=response,
            parse_mode='Markdown',
            reply_markup=get_main_menu(),
            context=context
        )

    async def show_gpt_tips(self, update, context):
        """–ü–æ–∫–∞–∑–∞—Ç—å GPT —Å–æ–≤–µ—Ç—ã"""
        tips = [
            "*–î–õ–Ø –õ–£–ß–®–ï–ì–û GPT –ê–ù–ê–õ–ò–ó–ê:* –î–æ–±–∞–≤—å—Ç–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏",
            "*–ß–ò–°–õ–û–í–´–ï –î–ê–ù–ù–´–ï:* GPT –ª—É—á—à–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏",
            "*–ö–û–ù–¢–ï–ö–°–¢:* –£–∫–∞–∂–∏—Ç–µ —Ç–∏–ø –±–∏–∑–Ω–µ—Å–∞ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∫ –¥–∞–Ω–Ω—ã–º",
            "*–ò–°–¢–û–†–ò–Ø:* –î–∞–Ω–Ω—ã–µ –∑–∞ 2+ –≥–æ–¥–∞ –¥–∞—é—Ç –ª—É—á—à–∏–µ –ø—Ä–æ–≥–Ω–æ–∑—ã",
            "*–¶–ï–õ–ò:* –ß–µ—Ç–∫–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å"
        ]

        tip = random.choice(tips)

        response = f"*GPT –°–û–í–ï–¢*\n\n{tip}\n\n"
        response += "*–•–û–¢–ò–¢–ï –õ–£–ß–®–ò–ô –ê–ù–ê–õ–ò–ó?*\n"
        response += "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n"
        response += "2. –í–∫–ª—é—á–∏—Ç–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏\n"
        response += "3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞"

        await self.safe_send_message(
            chat_id=update.effective_chat.id,
            text=response,
            parse_mode='Markdown',
            reply_markup=get_main_menu(),
            context=context
        )

    async def show_gpt_settings(self, update, context):
        """–ü–æ–∫–∞–∑–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ GPT"""
        status = "–ù–ê–°–¢–†–û–ï–ù" if GPT_AVAILABLE else "–¢–†–ï–ë–£–ï–¢ –ù–ê–°–¢–†–û–ô–ö–ò"

        response = f"*–ù–ê–°–¢–†–û–ô–ö–ò GPT –ê–ù–ê–õ–ò–ó–ê*\n\n"
        response += f"–°—Ç–∞—Ç—É—Å: {status}\n\n"

        response += "*–¢–ï–ö–£–©–ò–ï –ù–ê–°–¢–†–û–ô–ö–ò:*\n"
        response += f"‚Ä¢ –ú–æ–¥–µ–ª—å: {self.gpt_settings['model']}\n"
        response += f"‚Ä¢ –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {self.gpt_settings['temperature']}\n"
        response += f"‚Ä¢ –ú–∞–∫—Å. —Ç–æ–∫–µ–Ω–æ–≤: {self.gpt_settings['max_tokens']}\n\n"

        if not GPT_AVAILABLE:
            response += "‚ùå *GPT –ê–ù–ê–õ–ò–ó –ù–ï –î–û–°–¢–£–ü–ï–ù*\n\n"
            response += "*–ü–†–ò–ß–ò–ù–ê:* –ù–µ—Ç OpenAI API –∫–ª—é—á–∞\n\n"
            response += "*–ö–ê–ö –ò–°–ü–†–ê–í–ò–¢–¨:*\n"
            response += "1. –ü–æ–ª—É—á–∏—Ç–µ –∫–ª—é—á –Ω–∞ platform.openai.com\n"
            response += "2. –î–æ–±–∞–≤—å—Ç–µ –≤ .env —Ñ–∞–π–ª:\n"
            response += "   OPENAI_API_KEY=sk-–≤–∞—à_–∫–ª—é—á\n"
            response += "3. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –±–æ—Ç–∞\n\n"
            response += "*–ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ê:* –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å"

        await self.safe_send_message(
            chat_id=update.effective_chat.id,
            text=response,
            parse_mode='Markdown',
            reply_markup=get_gpt_settings_menu(),
            context=context
        )

    async def show_model_settings(self, query, context):
        """–ü–æ–∫–∞–∑–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏"""
        response = f"""
*–ù–ê–°–¢–†–û–ô–ö–ò –ú–û–î–ï–õ–ò GPT*

–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {self.gpt_settings['model']}

*–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:*
‚Ä¢ GPT-3.5 Turbo - –±—ã—Å—Ç—Ä—ã–π –∏ —ç–∫–æ–Ω–æ–º–∏—á–Ω—ã–π
‚Ä¢ GPT-4 - –±–æ–ª–µ–µ —É–º–Ω—ã–π –∏ —Ç–æ—á–Ω—ã–π
‚Ä¢ GPT-4 Turbo - –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞
‚Ä¢ GPT-4o - –ø–æ—Å–ª–µ–¥–Ω—è—è –∏ —Å–∞–º–∞—è –º–æ—â–Ω–∞—è

*–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:*
‚Ä¢ –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: GPT-3.5 Turbo
‚Ä¢ –î–ª—è —Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: GPT-4
‚Ä¢ –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á: GPT-4 Turbo –∏–ª–∏ GPT-4o

–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:
        """

        await self.safe_edit_callback_message(
            query=query,
            text=response,
            parse_mode='Markdown',
            reply_markup=get_model_settings_menu()
        )

    async def set_model(self, query, context, model_name):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å GPT"""
        self.gpt_settings['model'] = model_name

        response = f"""
‚úÖ *–ú–û–î–ï–õ–¨ –£–°–¢–ê–ù–û–í–õ–ï–ù–ê*

–ù–æ–≤–∞—è –º–æ–¥–µ–ª—å: {model_name}

–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã. –û–Ω–∏ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤ —Å–ª–µ–¥—É—é—â–∏—Ö GPT –∞–Ω–∞–ª–∏–∑–∞—Ö.

*–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:* –î–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –±–æ—Ç–∞.
        """

        await self.safe_edit_callback_message(
            query=query,
            text=response,
            parse_mode='Markdown',
            reply_markup=get_gpt_settings_menu()
        )

    async def show_context_settings(self, query, context):
        """–ü–æ–∫–∞–∑–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        response = f"""
*–ù–ê–°–¢–†–û–ô–ö–ò –ö–û–ù–¢–ï–ö–°–¢–ê –ê–ù–ê–õ–ò–ó–ê*

*–¢–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:*
‚Ä¢ –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {self.gpt_settings['temperature']}
‚Ä¢ –ú–∞–∫—Å. —Ç–æ–∫–µ–Ω–æ–≤: {self.gpt_settings['max_tokens']}

*–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞:* 
‚Ä¢ 0.0 - –±–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
‚Ä¢ 0.7 - –±–∞–ª–∞–Ω—Å –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏
‚Ä¢ 1.0 - –±–æ–ª–µ–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã

*–ú–∞–∫—Å. —Ç–æ–∫–µ–Ω–æ–≤:* 
‚Ä¢ 500-1000 –¥–ª—è –∫—Ä–∞—Ç–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤
‚Ä¢ 1000-2000 –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤
‚Ä¢ 2000-4000 –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤

*–î–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –¥–æ–±–∞–≤—å—Ç–µ –≤ config.py:*
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=1000
        """

        await self.safe_edit_callback_message(
            query=query,
            text=response,
            parse_mode='Markdown',
            reply_markup=get_gpt_settings_menu()
        )

    async def show_api_key_help(self, query, context):
        """–ü–æ–º–æ—â—å –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ API –∫–ª—é—á–∞"""
        response = """
*–ù–ê–°–¢–†–û–ô–ö–ê OPENAI API –ö–õ–Æ–ß–ê*

*–®–ê–ì–ò:*
1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ platform.openai.com
2. –í–æ–π–¥–∏—Ç–µ –≤ –∞–∫–∫–∞—É–Ω—Ç (–∏–ª–∏ —Å–æ–∑–¥–∞–π—Ç–µ)
3. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ —Ä–∞–∑–¥–µ–ª API Keys
4. –ù–∞–∂–º–∏—Ç–µ "Create new secret key"
5. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –∫–ª—é—á (–Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å sk-)

*–î–û–ë–ê–í–õ–ï–ù–ò–ï –í –ü–†–û–ï–ö–¢:*
1. –û—Ç–∫—Ä–æ–π—Ç–µ —Ñ–∞–π–ª `.env` –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
2. –î–æ–±–∞–≤—å—Ç–µ —Å—Ç—Ä–æ–∫—É:
   OPENAI_API_KEY=sk-–≤–∞—à_–∫–ª—é—á_–∑–¥–µ—Å—å
3. –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ —Ñ–∞–π–ª
4. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –±–æ—Ç–∞

*–°–¢–û–ò–ú–û–°–¢–¨:*
‚Ä¢ –ü–µ—Ä–≤—ã–µ $5 –±–µ—Å–ø–ª–∞—Ç–Ω–æ (–Ω–æ–≤—ã–µ –∞–∫–∫–∞—É–Ω—Ç—ã)
‚Ä¢ ~$0.002 –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤ (~750 —Å–ª–æ–≤)
‚Ä¢ ~$0.02 –∑–∞ —Ç–∏–ø–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑

*–í–ê–ñ–ù–û:*
‚Ä¢ –ù–∏–∫–æ–º—É –Ω–µ –ø–µ—Ä–µ–¥–∞–≤–∞–π—Ç–µ –≤–∞—à –∫–ª—é—á
‚Ä¢ –•—Ä–∞–Ω–∏—Ç–µ –µ–≥–æ –≤ .env —Ñ–∞–π–ª–µ (–Ω–µ –≤ –∫–æ–¥–µ)
‚Ä¢ –°–ª–µ–¥–∏—Ç–µ –∑–∞ —Ä–∞—Å—Ö–æ–¥–æ–º –≤ –∫–∞–±–∏–Ω–µ—Ç–µ OpenAI

*–ü–û–î–î–ï–†–ñ–ö–ê:* @alex_lyubovenko
        """

        await self.safe_edit_callback_message(
            query=query,
            text=response,
            parse_mode='Markdown',
            reply_markup=get_gpt_settings_menu()
        )

    async def back_to_settings(self, query, context):
        """–í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º"""
        status = "–ù–ê–°–¢–†–û–ï–ù" if GPT_AVAILABLE else "–¢–†–ï–ë–£–ï–¢ –ù–ê–°–¢–†–û–ô–ö–ò"

        response = f"*–ù–ê–°–¢–†–û–ô–ö–ò GPT –ê–ù–ê–õ–ò–ó–ê*\n\n"
        response += f"–°—Ç–∞—Ç—É—Å: {status}\n\n"

        response += "*–¢–ï–ö–£–©–ò–ï –ù–ê–°–¢–†–û–ô–ö–ò:*\n"
        response += f"‚Ä¢ –ú–æ–¥–µ–ª—å: {self.gpt_settings['model']}\n"
        response += f"‚Ä¢ –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {self.gpt_settings['temperature']}\n"
        response += f"‚Ä¢ –ú–∞–∫—Å. —Ç–æ–∫–µ–Ω–æ–≤: {self.gpt_settings['max_tokens']}\n\n"

        if not GPT_AVAILABLE:
            response += "‚ùå *GPT –ê–ù–ê–õ–ò–ó –ù–ï –î–û–°–¢–£–ü–ï–ù*\n\n"
            response += "*–ü–†–ò–ß–ò–ù–ê:* –ù–µ—Ç OpenAI API –∫–ª—é—á–∞\n\n"
            response += "*–ö–ê–ö –ò–°–ü–†–ê–í–ò–¢–¨:*\n"
            response += "1. –ü–æ–ª—É—á–∏—Ç–µ –∫–ª—é—á –Ω–∞ platform.openai.com\n"
            response += "2. –î–æ–±–∞–≤—å—Ç–µ –≤ .env —Ñ–∞–π–ª:\n"
            response += "   OPENAI_API_KEY=sk-–≤–∞—à_–∫–ª—é—á\n"
            response += "3. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –±–æ—Ç–∞\n\n"
            response += "*–ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ê:* –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å"

        await self.safe_edit_callback_message(
            query=query,
            text=response,
            parse_mode='Markdown',
            reply_markup=get_gpt_settings_menu()
        )

    async def back_to_main(self, query, context):
        """–í–µ—Ä–Ω—É—Ç—å—Å—è –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"""
        await self.safe_edit_callback_message(
            query=query,
            text="*–ì–õ–ê–í–ù–û–ï –ú–ï–ù–Æ*",
            parse_mode='Markdown',
            reply_markup=get_main_menu()
        )

    async def cancel_operation(self, query, context, user_id):
        """–û—Ç–º–µ–Ω–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ callback"""
        if user_id in self.user_data:
            # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            self.user_data.pop(user_id, None)

        await self.safe_edit_callback_message(
            query=query,
            text="‚úÖ –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞. –í—Å–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —É–¥–∞–ª–µ–Ω—ã.",
            parse_mode=None,
            reply_markup=get_main_menu()
        )

    # ========== –ó–ê–ü–£–°–ö –ë–û–¢–ê ==========
    def run(self):
        """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
        try:
            # –°–æ–∑–¥–∞–µ–º Application
            application = Application.builder().token(TOKEN).build()

            # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥
            application.add_handler(CommandHandler("start", self.start_command))
            application.add_handler(CommandHandler("help", self.help_command))
            application.add_handler(CommandHandler("cancel", self.cancel_command))
            application.add_handler(CommandHandler("stats", self.stats_command))
            application.add_handler(CommandHandler("admin_stats", self.admin_stats_command))

            # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ callback
            application.add_handler(CallbackQueryHandler(self.handle_callback))

            # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            application.add_handler(MessageHandler(filters.Document.ALL, self.handle_document))

            # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (–ø–æ—Å–ª–µ–¥–Ω–∏–º–∏)
            application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_message))

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
            async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
                logger.error(f"–û—à–∏–±–∫–∞: {context.error}", exc_info=True)
                if update and update.effective_user:
                    try:
                        await context.bot.send_message(
                            chat_id=update.effective_user.id,
                            text="‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
                        )
                    except:
                        pass

            application.add_error_handler(error_handler)

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–ø—É—Å–∫–µ
            print("\n" + "=" * 60)
            print("üöÄ GPT BUSINESS AUDITOR BOT –ó–ê–ü–£–©–ï–ù!")
            print("=" * 60)
            print(f"üìä GPT –∞–Ω–∞–ª–∏–∑: {'‚úÖ –î–û–°–¢–£–ü–ï–ù' if GPT_AVAILABLE else '‚ö†Ô∏è –¢–†–ï–ë–£–ï–¢ –ù–ê–°–¢–†–û–ô–ö–ò'}")
            print(f"üë§ –ê–¥–º–∏–Ω: {ADMIN_ID if ADMIN_ID else '–ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω'}")
            print(f"üìÅ –ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {MAX_FILE_SIZE / 1024 / 1024:.0f} MB")
            print(f"üóÑÔ∏è  –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {self.db.db_path}")
            print(f"üìä Rate limit: {self.MAX_GPT_REQUESTS_PER_DAY} –∑–∞–ø—Ä–æ—Å–æ–≤/–¥–µ–Ω—å")
            print("=" * 60)
            print("\nüì± –û—Ç–∫—Ä–æ–π—Ç–µ Telegram")
            print("üîç –ù–∞–π–¥–∏—Ç–µ –≤–∞—à–µ–≥–æ –±–æ—Ç–∞")
            print("üí¨ –ù–∞–ø–∏—à–∏—Ç–µ /start")
            print("ü§ñ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ GPT –∞–Ω–∞–ª–∏–∑")
            print("üëã Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
            print("\n" + "=" * 60)

            # –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
            application.run_polling(
                allowed_updates=Update.ALL_TYPES,
                drop_pending_updates=True,
                close_loop=False
            )

        except KeyboardInterrupt:
            print("\nüëã –ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        except Exception as e:
            logger.critical(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –±–æ—Ç–∞: {e}")
            print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)


# ========== –ó–ê–ü–£–°–ö ==========
if __name__ == "__main__":
    print("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GPT Business Auditor Bot...")

    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–∫–µ–Ω –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º
        if not TOKEN or TOKEN == "your_actual_bot_token_here":
            print("\n‚ùå –û–®–ò–ë–ö–ê: –¢–æ–∫–µ–Ω –±–æ—Ç–∞ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω!")
            print("   –î–æ–±–∞–≤—å—Ç–µ TELEGRAM_BOT_TOKEN –≤ .env —Ñ–∞–π–ª")
            print("   –ü—Ä–∏–º–µ—Ä .env —Ñ–∞–π–ª–∞:")
            print("   TELEGRAM_BOT_TOKEN=–≤–∞—à_–Ω–æ–≤—ã–π_—Ç–æ–∫–µ–Ω_–æ—Ç_botfather")
            print("   TELEGRAM_ADMIN_ID=427861947")
            print("   OPENAI_API_KEY=sk-–≤–∞—à_–∫–ª—é—á_openai")
            sys.exit(1)

        bot = GPTBusinessBot()
        bot.run()

    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–æ—Ç–∞: {e}")